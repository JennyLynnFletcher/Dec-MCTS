{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c186d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import rospy\n",
    "from std_msgs.msg import String\n",
    "from geometry_msgs.msg import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b19302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloTreeSearchNode():\n",
    "    def __init__(self, state, parent=None, parent_action=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.parent_action = parent_action\n",
    "        self.children = []\n",
    "        self._number_of_visits = 0\n",
    "        self._results = defaultdict(int)\n",
    "        self._results[1] = 0\n",
    "        self._results[-1] = 0\n",
    "        self._untried_actions = None\n",
    "        self._untried_actions = self.untried_actions()\n",
    "        return\n",
    "\n",
    "    def untried_actions(self):\n",
    "\n",
    "        self._untried_actions = self.state.get_legal_actions()\n",
    "        return self._untried_actions\n",
    "\n",
    "    def q(self):\n",
    "        '''\n",
    "        Update to reflect robot scenario rather than wins and losses\n",
    "        '''\n",
    "        wins = self._results[1]\n",
    "        loses = self._results[-1]\n",
    "        return wins - loses\n",
    "\n",
    "    def n(self):\n",
    "        return self._number_of_visits\n",
    "\n",
    "    def expand(self):\n",
    "\n",
    "        action = self._untried_actions.pop()\n",
    "        next_state = self.state.move(action)\n",
    "        child_node = MonteCarloTreeSearchNode(\n",
    "            next_state, parent=self, parent_action=action)\n",
    "\n",
    "        self.children.append(child_node)\n",
    "        return child_node \n",
    "\n",
    "    def is_terminal_node(self):\n",
    "        return self.state.is_game_over()\n",
    "\n",
    "    def simulation(self):\n",
    "        current_simulation_state = self.state\n",
    "\n",
    "        while not current_simulation_state.is_game_over():\n",
    "\n",
    "            possible_moves = current_simulation_state.get_legal_actions()\n",
    "\n",
    "            action = self.simulation_policy(possible_moves)\n",
    "            current_simulation_state = current_simulation_state.move(action)\n",
    "        return current_simulation_state.game_result()\n",
    "\n",
    "    def backpropagate(self, result):\n",
    "        self._number_of_visits += 1.\n",
    "        self._results[result] += 1.\n",
    "        if self.parent:\n",
    "            self.parent.backpropagate(result)\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self._untried_actions) == 0\n",
    "\n",
    "    def best_child(self, c_param=0.1):\n",
    "\n",
    "        choices_weights = [(c.q() / c.n()) + c_param * np.sqrt((2 * np.log(self.n()) / c.n())) for c in self.children]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def simulation_policy(self, possible_moves):\n",
    "\n",
    "        return possible_moves[np.random.randint(len(possible_moves))]\n",
    "\n",
    "    def _tree_policy(self):\n",
    "\n",
    "        current_node = self\n",
    "        while not current_node.is_terminal_node():\n",
    "\n",
    "            if not current_node.is_fully_expanded():\n",
    "                return current_node.expand()\n",
    "            else:\n",
    "                current_node = current_node.best_child()\n",
    "        return current_node\n",
    "\n",
    "    def best_action(self):\n",
    "        simulation_no = 100\n",
    "\n",
    "\n",
    "        for i in range(simulation_no):\n",
    "\n",
    "            v = self._tree_policy()\n",
    "            reward = v.simulation()\n",
    "            v.backpropagate(reward)\n",
    "\n",
    "        return self.best_child(c_param=0.)\n",
    "\n",
    "    def get_legal_actions(self): \n",
    "        '''\n",
    "        Modify according to your game or\n",
    "        needs. Constructs a list of all\n",
    "        possible actions from current state.\n",
    "        Returns a list.\n",
    "        '''\n",
    "\n",
    "    def is_game_over(self):\n",
    "        '''\n",
    "        Modify according to your game or \n",
    "        needs. It is the game over condition\n",
    "        and depends on your game. Returns\n",
    "        true or false\n",
    "        '''\n",
    "\n",
    "    def game_result(self):\n",
    "        '''\n",
    "        Modify according to your game or \n",
    "        needs. Returns 1 or 0 or -1 depending\n",
    "        on your state corresponding to win,\n",
    "        tie or a loss.\n",
    "        '''\n",
    "\n",
    "    def move(self,action):\n",
    "        '''\n",
    "        Modify according to your game or \n",
    "        needs. Changes the state of your \n",
    "        board with a new value. For a normal\n",
    "        Tic Tac Toe game, it can be a 3 by 3\n",
    "        array with all the elements of array\n",
    "        being 0 initially. 0 means the board \n",
    "        position is empty. If you place x in\n",
    "        row 2 column 3, then it would be some \n",
    "        thing like board[2][3] = 1, where 1\n",
    "        represents that x is placed. Returns \n",
    "        the new state after making a move.\n",
    "        '''\n",
    "\n",
    "def main():\n",
    "    root = MonteCarloTreeSearchNode(state = initial_state)\n",
    "    selected_node = root.best_action()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e89805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot():\n",
    "    def __init__(self, robot_id, start_loc, goal_loc, time_interval, env):\n",
    "        self.robot_id = robot_id\n",
    "        self.start_loc = start_loc\n",
    "        self.goal_loc = goal_loc\n",
    "        self.loc_list = []\n",
    "        self.observations_list = []\n",
    "        self.time_interval = time_interval\n",
    "        self.env = None\n",
    "        self.pub = rospy.Publisher('robot_loc_'+robot_id, Point, queue_size=10)\n",
    "        rospy.init_node('robot_'+robot_id , anonymous=True)\n",
    "        self.rate = rospy.Rate(1/time_interval)\n",
    "        \n",
    "    def register_env(self, env):\n",
    "        '''\n",
    "        Associates an Environment object with the robot\n",
    "        '''\n",
    "        self.env = env\n",
    "        \n",
    "    def get_observations(self):\n",
    "        '''\n",
    "        Return a dictionary of N,E,S,W and whether there\n",
    "        is a wall in that direction from the robot's current \n",
    "        location\n",
    "        '''\n",
    "        return self.env.get_walls_from_loc(loc_list[-1])\n",
    "        \n",
    "    def move(self, direction):\n",
    "        '''\n",
    "        Move one step in direction passed as argument\n",
    "        if fail due to obstructing wall from get_observations()\n",
    "        stay in same location\n",
    "        '''\n",
    "        \n",
    "    def update(self):\n",
    "        '''\n",
    "        Move to next position, update observations, update locations, run MCTS,\n",
    "        publish to ROS topic\n",
    "        '''\n",
    "        \n",
    "    def listener(self):\n",
    "        '''\n",
    "        Implement timer listener at frequency 1/time_interval to call to update() \n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, width, height, walls, start, goal, render_interval=0.5):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.walls = walls\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.render_interval = render_interval\n",
    "        self.timestep = 0\n",
    "        self.complete = False\n",
    "        self.robot_list = [] #Tuple of robot ID and location\n",
    "        \n",
    "    def add_robot(self, robot):\n",
    "        '''\n",
    "        Add robot with start location start_loc, goal goal_loc and pass self as env\n",
    "        Add to self.robot_list\n",
    "        ''' \n",
    "        \n",
    "    def get_walls_from_loc(self, loc):\n",
    "        '''\n",
    "        return a dictionary of N,E,S,W and whether there\n",
    "        is a wall in that direction from loc \n",
    "        '''\n",
    "        \n",
    "    def render(self):\n",
    "        '''\n",
    "        render\n",
    "        '''\n",
    "    \n",
    "    def update_loc(self, loc_msg):\n",
    "        '''\n",
    "        Callback function for robot locations\n",
    "        Update locations of robots for rendering\n",
    "        '''\n",
    "        \n",
    "    def listener(self):\n",
    "        '''\n",
    "        Implement listener code, call to update_loc()\n",
    "        Implement timer listener at frequency 1/render_interval to call to render()\n",
    "        '''\n",
    "        rospy.init_node('Environment', anonymous=True)\n",
    "        for (robot_id,_) in self.robot_list:\n",
    "            rospy.Subscriber('robot_loc_'+robot_id, Point, update_loc, robot_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9dbdc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import json\n",
    "\n",
    "def json_dumps_tuple_keys(mapping):\n",
    "    string_keys = {json.dumps(k): v for k, v in mapping.items()}\n",
    "    return json.dumps(string_keys)\n",
    "\n",
    "def json_loads_tuple_keys(string):\n",
    "    mapping = json.loads(string)\n",
    "    return {tuple(json.loads(k)): v for k, v in mapping.items()}\n",
    "\n",
    "def Agent_Info_from_JSON(json_str):\n",
    "    json_dict = json.loads(json_str)\n",
    "    state = Agent_State(json_dict['state']['loc'], json_dict['state']['obs'])\n",
    "    probs = json_loads_tuple_keys(json_dict['probs'])\n",
    "    timestamp = json_dict['time']\n",
    "    robot_id = json_dict['robot_id']\n",
    "    return Agent_Info(robot_id, state, probs, timestamp)\n",
    "\n",
    "class Agent_State():\n",
    "    def __init__(self, location, observations):\n",
    "        self.loc = location\n",
    "        self.obs = observations\n",
    "\n",
    "class Agent_Info():\n",
    "    def __init__(self, robot_id, state, probs, timestamp):\n",
    "        self.state = state #Type of Agent_State\n",
    "        self.probs = json_dumps_tuple_keys(probs) #Dictionary: use JSON - use json_loads_tuple_keys() to turn back to normal tuple\n",
    "        self.time = timestamp #integer - number of times update called with execute action True\n",
    "        self.robot_id = robot_id #UUID      \n",
    "        \n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, \n",
    "            sort_keys=True, indent=4)\n",
    "\n",
    "    def select_random_plan(self):\n",
    "        plan, _ = np.random.choice(self.probs.keys, p=self.probs.values).copy()\n",
    "        return plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff5bca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent_Info(0, Agent_State((4,5),[(1,2),(2,3)]), {(5,7):0.6, (4,8):0.3}, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2ef1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.toJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92ed389e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probs': '{\"[5, 7]\": 0.6, \"[4, 8]\": 0.3}',\n",
       " 'robot_id': 0,\n",
       " 'state': {'loc': [4, 5], 'obs': [[1, 2], [2, 3]]},\n",
       " 'time': 10}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90feb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Agent_Info_from_JSON(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaaec588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.robot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec6efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
